import os
import glob
import numpy as np
from PIL import Image
from datetime import datetime

import torch
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as T
import torch.nn as nn
import torch.optim as optim

from R2U_Net.r2_unet_model import R2UNet

'''
ë³€ê²½ì‚¬í•­
1) Epoch 20 â†’ 40
2) Early Stopping ì¶”ê°€: val_lossê°€ ì¼ì • íšŸìˆ˜ ì´ìƒ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¢…ë£Œ
'''

# ====================== ë°ì´í„°ì…‹ ì •ì˜ ======================
class ForestDataset(Dataset):
    def __init__(self, img_dir, mask_dir, transform_img=None, transform_mask=None):
        self.transform_img = transform_img
        self.transform_mask = transform_mask

        image_files = glob.glob(os.path.join(img_dir, '*.tif'))
        mask_files = glob.glob(os.path.join(mask_dir, '*.tif'))

        def core_name(f, is_mask=False):
            name = os.path.splitext(os.path.basename(f))[0]
            if is_mask and name.endswith('_FGT'):
                name = name.replace('_FGT', '')
            return name

        image_dict = {core_name(f): f for f in image_files}
        mask_dict = {core_name(f, is_mask=True): f for f in mask_files}

        common_keys = sorted(set(image_dict.keys()) & set(mask_dict.keys()))
        self.img_paths = [image_dict[k] for k in common_keys]
        self.mask_paths = [mask_dict[k] for k in common_keys]

        print(f"ì´ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜: {len(image_files)}")
        print(f"ì´ ë§ˆìŠ¤í¬ íŒŒì¼ ìˆ˜: {len(mask_files)}")
        print(f"ìŒì´ ë§ëŠ” ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ê°œìˆ˜: {len(self.img_paths)}")

        self.mapping = {
            0: 0, 180: 0,
            110: 1, 120: 1, 130: 1,
            140: 2,
            190: 3
        }

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img = Image.open(self.img_paths[idx]).convert('RGB')
        mask = Image.open(self.mask_paths[idx]).convert('L')

        if self.transform_img:
            img = self.transform_img(img)

        if self.transform_mask:
            mask = self.transform_mask(mask)
            mask_np = mask.numpy()
            new_mask = np.zeros_like(mask_np, dtype=np.int64)
            for k, v in self.mapping.items():
                new_mask[mask_np == k] = v
            mask = torch.from_numpy(new_mask)

        return img, mask

# ====================== ì „ì²˜ë¦¬ í•¨ìˆ˜ ======================
def squeeze_mask(x):
    return x.squeeze(0)

# ====================== ê²€ì¦ í•¨ìˆ˜ ======================
def validate(model, val_loader, criterion, device, num_classes):
    model.eval()
    val_loss = 0.0
    total_correct = 0
    total_pixels = 0
    iou_scores = np.zeros(num_classes)
    class_counts = np.zeros(num_classes)

    with torch.no_grad():
        for imgs, masks in val_loader:
            imgs = imgs.to(device)
            masks = masks.to(device)

            outputs = model(imgs)
            loss = criterion(outputs, masks)
            val_loss += loss.item() * imgs.size(0)

            preds = torch.argmax(outputs, dim=1)

            total_correct += (preds == masks).sum().item()
            total_pixels += masks.numel()

            for cls in range(num_classes):
                pred_inds = (preds == cls)
                target_inds = (masks == cls)
                intersection = (pred_inds & target_inds).sum().item()
                union = (pred_inds | target_inds).sum().item()
                if union > 0:
                    iou_scores[cls] += intersection / union
                    class_counts[cls] += 1

    val_loss /= len(val_loader.dataset)
    pixel_acc = total_correct / total_pixels
    mean_iou = np.mean([iou_scores[i] / class_counts[i] if class_counts[i] > 0 else 0 for i in range(num_classes)])

    return val_loss, pixel_acc, mean_iou

# ====================== ë©”ì¸ ì‹¤í–‰ ======================
if __name__ == '__main__':
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    BATCH_SIZE = 4
    EPOCHS = 80
    LR = 1e-3
    VAL_RATIO = 0.2
    NUM_CLASSES = 4

    # Early Stopping ì„¤ì •
    patience = 5
    min_delta = 0.001
    early_stop_counter = 0

    transform_img = T.Compose([
        T.Resize((512, 512)),
        T.ToTensor(),
    ])

    transform_mask = T.Compose([
        T.Resize((512, 512), interpolation=Image.NEAREST),
        T.PILToTensor(),
        squeeze_mask,
    ])

    full_dataset = ForestDataset(
        img_dir='./data/Training/origin/AP_IMAGE_512/',
        mask_dir='./data/Training/label/AP_512/FGT_TIF/',
        transform_img=transform_img,
        transform_mask=transform_mask
    )

    val_size = int(len(full_dataset) * VAL_RATIO)
    train_size = len(full_dataset) - val_size
    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])
    print(f"í•™ìŠµ ì„¸íŠ¸ í¬ê¸°: {train_size}, ê²€ì¦ ì„¸íŠ¸ í¬ê¸°: {val_size}")

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    model = R2UNet(n_channels=3, n_classes=NUM_CLASSES, t=1).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)

    best_val_loss = float('inf')
    best_model_path = 'r2unet_forest_best.pth'

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0

        for batch_idx, (imgs, masks) in enumerate(train_loader):
            imgs = imgs.to(DEVICE)
            masks = masks.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * imgs.size(0)

        epoch_loss = running_loss / len(train_dataset)
        val_loss, pixel_acc, mean_iou = validate(model, val_loader, criterion, DEVICE, NUM_CLASSES)

        print(f"ğŸ“˜ Epoch {epoch+1} ê²°ê³¼:", flush=True)
        print(f"    Train Loss: {epoch_loss:.4f}", flush=True)
        print(f"    Val Loss:   {val_loss:.4f}", flush=True)
        print(f"    Pixel Acc:  {pixel_acc:.4f}", flush=True)
        print(f"    Mean IoU:   {mean_iou:.4f}", flush=True)


        # ëª¨ë¸ ê°œì„  ì—¬ë¶€ í™•ì¸
        if best_val_loss - val_loss > min_delta:
            best_val_loss = val_loss
            torch.save(model.state_dict(), best_model_path)
            print(f"âœ¨ ìƒˆë¡œìš´ ìµœì  ëª¨ë¸ ì €ì¥ë¨: {best_model_path}")
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            print(f"â³ EarlyStopping ê²½ê³¼: {early_stop_counter}/{patience}")

        if early_stop_counter >= patience:
            print(f"ğŸ›‘ Early stopping ì ìš©ë¨ (patience: {patience})")
            break

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_filename = f'r2unet_forest_{timestamp}.pth'
    torch.save(model.state_dict(), model_filename)
    print(f"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}")
